{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modelos basados en aprendizaje profundo y de atencion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITPSJ8YUqN4H"
      },
      "source": [
        "from google.colab import drive  # Se conecta a drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrdNespHsi4Q"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt7Sxp7Aqht4"
      },
      "source": [
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, LSTM, Bidirectional\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from skimage.io import imread\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5TwAQwlsldi"
      },
      "source": [
        "# Hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF7o-FNTsnOL"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "img_size = 224\n",
        "nb_crops = 3\n",
        "nb_channels = 3\n",
        "seed = 2021"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fzj0OIaQswbg"
      },
      "source": [
        "# Carga de datos\n",
        "\n",
        "Primero hay que cargar en el entorno de ejecución los datos generados con la libreta `Preprocesamiento_de_imágenes.ipynb`. Para ello se han comprimido todos los datos preprocesados en 5 archivos `.zip` Con estos 5 archivos hay que realizar este proceso:\n",
        "\n",
        "\n",
        "1.   Se copian los 5 archivos comprimidos con las imágenes.\n",
        "2.   Se descomprimen.\n",
        "3.   Se eliminan los archivos comprimidos (opcional, es para ahorrar espacio)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBSDdZXL4y0J"
      },
      "source": [
        "**Importante!!!** La variable ruta debe contener la dirección en la que se han almacenado los `.zip`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fl5fYKs4SjN"
      },
      "source": [
        "ruta = './drive/MyDrive/TFG/datos/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNf6fh2Bs1bt"
      },
      "source": [
        "!cp $ruta'datasetAVA_1.zip' AVADataset1.zip\n",
        "!cp $ruta'datasetAVA_2.zip' AVADataset2.zip\n",
        "!cp $ruta'datasetAVA_3.zip' AVADataset3.zip\n",
        "!cp $ruta'datasetAVA_4.zip' AVADataset4.zip\n",
        "!cp $ruta'datasetAVA_5.zip' AVADataset5.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujx_ip5Vs2Z-"
      },
      "source": [
        "!unzip -q AVADataset1.zip\n",
        "!unzip -q AVADataset2.zip\n",
        "!unzip -q AVADataset3.zip\n",
        "!unzip -q AVADataset4.zip\n",
        "!unzip -q AVADataset5.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImUo4gAps4Bl"
      },
      "source": [
        "!rm AVADataset1.zip\n",
        "!rm AVADataset2.zip\n",
        "!rm AVADataset3.zip\n",
        "!rm AVADataset4.zip\n",
        "!rm AVADataset5.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1S--OCqHs5e0"
      },
      "source": [
        "Se comprueba que están las 255.353 imágenes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTbMOKQDs6DV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67656947-6dee-427e-a4c1-e656162385db"
      },
      "source": [
        "# Se comprueba que cada carpeta tiene 10.000 imagenes. La ultima solo tiene que tener 5353\n",
        "for i in range(1,27):\n",
        "  print(\"Iteracion \", i, \". Archivos: \", len(os.listdir('./X'+str(i))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteracion  1 . Archivos:  10000\n",
            "Iteracion  2 . Archivos:  10000\n",
            "Iteracion  3 . Archivos:  10000\n",
            "Iteracion  4 . Archivos:  10000\n",
            "Iteracion  5 . Archivos:  10000\n",
            "Iteracion  6 . Archivos:  10000\n",
            "Iteracion  7 . Archivos:  10000\n",
            "Iteracion  8 . Archivos:  10000\n",
            "Iteracion  9 . Archivos:  10000\n",
            "Iteracion  10 . Archivos:  10000\n",
            "Iteracion  11 . Archivos:  10000\n",
            "Iteracion  12 . Archivos:  10000\n",
            "Iteracion  13 . Archivos:  10000\n",
            "Iteracion  14 . Archivos:  10000\n",
            "Iteracion  15 . Archivos:  10000\n",
            "Iteracion  16 . Archivos:  10000\n",
            "Iteracion  17 . Archivos:  10000\n",
            "Iteracion  18 . Archivos:  10000\n",
            "Iteracion  19 . Archivos:  10000\n",
            "Iteracion  20 . Archivos:  10000\n",
            "Iteracion  21 . Archivos:  10000\n",
            "Iteracion  22 . Archivos:  10000\n",
            "Iteracion  23 . Archivos:  10000\n",
            "Iteracion  24 . Archivos:  10000\n",
            "Iteracion  25 . Archivos:  10000\n",
            "Iteracion  26 . Archivos:  5353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uarNDNHis8N9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "587b27bb-8f57-4edf-ec0e-0191b1979df8"
      },
      "source": [
        "# Se cargan el dataframe con la direccion de los archivos y la variable clase\n",
        "import pandas as pd\n",
        "dataset = pd.read_csv(ruta+'dataset.csv')\n",
        "\n",
        "dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>id</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>X1/0.npy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>X1/1.npy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>X1/2.npy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>X1/3.npy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>X1/4.npy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255348</th>\n",
              "      <td>255348</td>\n",
              "      <td>X26/5348.npy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255349</th>\n",
              "      <td>255349</td>\n",
              "      <td>X26/5349.npy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255350</th>\n",
              "      <td>255350</td>\n",
              "      <td>X26/5350.npy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255351</th>\n",
              "      <td>255351</td>\n",
              "      <td>X26/5351.npy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255352</th>\n",
              "      <td>255352</td>\n",
              "      <td>X26/5352.npy</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>255353 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        Unnamed: 0            id  Class\n",
              "0                0      X1/0.npy      1\n",
              "1                1      X1/1.npy      0\n",
              "2                2      X1/2.npy      1\n",
              "3                3      X1/3.npy      1\n",
              "4                4      X1/4.npy      1\n",
              "...            ...           ...    ...\n",
              "255348      255348  X26/5348.npy      1\n",
              "255349      255349  X26/5349.npy      1\n",
              "255350      255350  X26/5350.npy      1\n",
              "255351      255351  X26/5351.npy      1\n",
              "255352      255352  X26/5352.npy      1\n",
              "\n",
              "[255353 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPKTl4pxtB8j"
      },
      "source": [
        "Se divide el dataset en train, validation y test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SNHEyyytAeO"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tr , test = train_test_split(dataset, test_size=0.09, shuffle=True, random_state=seed, stratify=dataset['Class'])\n",
        "train , validation = train_test_split(tr, test_size=0.2, shuffle=True, random_state=seed, stratify=tr['Class'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7giBgbZntD-W"
      },
      "source": [
        "Se define un generador que recibirá el dataframe (dirección de las parches y la variable clase) e irá cargando los 9 parches preprocesados de las imágenes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APkuTIINtFO9"
      },
      "source": [
        "class Generator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, dataset, batch_size=512):\n",
        "        self.x = dataset['id'].to_numpy()\n",
        "        self.y = dataset['Class'].to_numpy()\n",
        "        self.batch_size = batch_size\n",
        "        print(\"Se han detectado \", len(self.x), \" elementos\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.x) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        \n",
        "        return np.array([np.load('./'+file_name)\n",
        "               for file_name in batch_x]), np.array(batch_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh714EJytG9v"
      },
      "source": [
        "Se define la capa de atención. Seguirá las fórmulas propuestas por Bahdanau."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Buc4mJM9tIgY"
      },
      "source": [
        "class Attention(Layer):\n",
        "\n",
        "  def __init__(self, units=1):\n",
        "    super(Attention, self).__init__()\n",
        "    self.W1 = tf.keras.layers.Dense(units)\n",
        "    self.W2 = tf.keras.layers.Dense(units)\n",
        "    self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, features, hidden):\n",
        "    hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "      \n",
        "    score = tf.nn.tanh(\n",
        "        self.W1(features) + self.W2(hidden_with_time_axis))\n",
        "\n",
        "    attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
        "\n",
        "    context_vector = attention_weights * features\n",
        "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moR2atlDtKX-"
      },
      "source": [
        "Se aplica la técnica de submuestreo sobre el conjunto de entrenamiento y de validación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i98sYLlbtLcP"
      },
      "source": [
        "# Se separan los registros con variable clase 0 de los de variable clase 1\n",
        "train_0 = train[train.Class == 0]\n",
        "train_1 = train[train.Class == 1]\n",
        "# Se aleatorizan los registros de la clase mayoritaria\n",
        "train_1 = train_1.sample(frac = 1, random_state=seed)\n",
        "\n",
        "# Se cogen los X primeros registros de la clase mayoritaria\n",
        "# siendo X la cantidad de registros de la clase minoritaria\n",
        "# para igualar la cantidad de registros que hay de ambas clases\n",
        "train_nuevo = train_1[0:len(train_0)]\n",
        "\n",
        "# Se concatenan\n",
        "train2 = pd.concat([train_0, train_nuevo])\n",
        "train2 = train2.sample(frac = 1, random_state=seed).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifDTBUabtMgZ"
      },
      "source": [
        "v_0 = validation[validation.Class == 0]\n",
        "v_1 = validation[validation.Class == 1]\n",
        "\n",
        "v_1 = v_1.sample(frac = 1, random_state=seed)\n",
        "v_nuevo = v_1[0:len(v_0)]\n",
        "\n",
        "val2 = pd.concat([v_0, v_nuevo])\n",
        "val2 = val2.sample(frac = 1, random_state=seed).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI2joWBErOLe"
      },
      "source": [
        "Se definen los generadores que se le pasarán como entrada a las redes neuronales."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGIo9JkXrK4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c2f1a93-7f92-4c74-8871-49bbba3b88c1"
      },
      "source": [
        "train_gen = Generator(train2)\n",
        "val_gen   = Generator(val2)\n",
        "test_gen  = Generator(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Se han detectado  107792  elementos\n",
            "Se han detectado  26948  elementos\n",
            "Se han detectado  22982  elementos\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rirUHEegtNXC"
      },
      "source": [
        "# Primer modelo basado en mecanismos de atención y redes LSTM\n",
        "\n",
        "Se define el primer modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4FVAfM9taCz"
      },
      "source": [
        "# Hiperparametros\n",
        "d_LSTM = 0.45\n",
        "units_LSTM = 9\n",
        "units_attention = 10\n",
        "\n",
        "# Modelo\n",
        "shape = (nb_crops*nb_crops, 1024)\n",
        "patches_procesados = tf.keras.layers.Input(shape=shape)\n",
        "\n",
        "# Capa bidireccional con unidades LSTM\n",
        "(lstm, forward_h, forward_c, backward_h, backward_c) = Bidirectional(LSTM(units_LSTM, return_sequences=True, return_state=True, dropout=d_LSTM))(patches_procesados)\n",
        "\n",
        "# Se concatenan las h (forward y backward)\n",
        "state_h = Concatenate()([forward_h, backward_h])\n",
        "\n",
        "# Se pasan a la capa de atencion\n",
        "context_vector, _ = Attention(units_attention)(lstm, state_h)\n",
        "\n",
        "output = Dense(1, activation=\"sigmoid\")(context_vector)\n",
        "\n",
        "model = keras.Model(inputs=patches_procesados, outputs=output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC4UzFJVtbBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea15b2c4-52ce-4326-8356-6496f954edc9"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 9, 1024)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 9, 18), (Non 74448       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 18)           0           bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "attention (Attention)           ((None, 18), (None,  391         bidirectional[0][0]              \n",
            "                                                                 concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            19          attention[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 74,858\n",
            "Trainable params: 74,858\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsZFB2achsv9"
      },
      "source": [
        "Antes de pasar al entrenamiento hay que compilarlo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkP8YY_wtdrg"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xiyf25Soh-p6"
      },
      "source": [
        "Se definen los callback que se le van a aplicar:\n",
        "\n",
        "\n",
        "*   Early Stopping: sirve para monitorizar el entrenamiento y pararlo cuando se detecte que no haya mejora para los datos de validación.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUTDRz9qtfNl"
      },
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1YbboKWkgoF"
      },
      "source": [
        "Se entrena al modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsgo-nBjtg-_"
      },
      "source": [
        "epochs = 50\n",
        " \n",
        "history = model.fit_generator(epochs=epochs, generator=train_gen, validation_data=val_gen, callbacks=early_stopping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvw7E0MEm6C3"
      },
      "source": [
        "Para evaluar al modelo se calcula el `accuracy` y el `balanced accuracy` para el conjunto de datos de prueba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kzsYnJ6m4KF"
      },
      "source": [
        "real = test['Class']\n",
        "\n",
        "pred = model.predict(test_gen)\n",
        "\n",
        "p=[]\n",
        "for x in pred:\n",
        "  if x > 0.5:\n",
        "    p.append(1.0)\n",
        "  else:\n",
        "    p.append(0.0)\n",
        "y_p = np.array(p)\n",
        "y_p\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_true=real, y_pred=y_p).ravel()\n",
        "print(\"Tp: \",tp,\" Fp: \",fp)\n",
        "print(\"Fn: \",fn,\" Tn:\", tn)\n",
        "\n",
        "sensitivity = tp / (tp+fn)\n",
        "specifity = tn / (fp+tn)\n",
        "\n",
        "print(\"Balanced accuracy: \", (sensitivity+specifity)/2)\n",
        "print(\"Accuracy: \", (tp+tn)/(tp+tn+fp+fn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndtEvvTQjpCv"
      },
      "source": [
        "Se puede guardar el modelo generado para usarlo posteriormente. **Importante!** Se puede cambiar la direccion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnYzjKDHtkuq"
      },
      "source": [
        "direccion = './drive/MyDrive/TFG/model1'\n",
        "tf.keras.models.save_model(model, direccion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YabTYPSrtQe7"
      },
      "source": [
        "# Segundo modelo basado en mecanismos de atención y redes LSTM\n",
        "\n",
        "Se define el segundo modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQ_-E0vatnKE"
      },
      "source": [
        "# Hiperparametros\n",
        "d_LSTM = 0.45\n",
        "units_LSTM = 9\n",
        "units_attention = 10\n",
        "\n",
        "# Modelo\n",
        "shape = (nb_crops*nb_crops, 1024)\n",
        "patches_procesados = tf.keras.layers.Input(shape=shape)\n",
        "\n",
        "patches = tf.split(patches_procesados, num_or_size_splits=9, axis=1)\n",
        "\n",
        "# Se agrupan los parches por filas\n",
        "row1 = tf.concat([patches[0], patches[1], patches[2]], axis=1)\n",
        "row2 = tf.concat([patches[3], patches[4], patches[5]], axis=1)\n",
        "row3 = tf.concat([patches[6], patches[7], patches[8]], axis=1)\n",
        "\n",
        "# Se agrupan los parches por columnas\n",
        "column1 = tf.concat([patches[0], patches[3], patches[6]], axis=1)\n",
        "column2 = tf.concat([patches[1], patches[4], patches[7]], axis=1)\n",
        "column3 = tf.concat([patches[2], patches[5], patches[8]], axis=1)\n",
        "\n",
        "# Se pasa cada grupo de una capa bidireccional con unidades LSTM\n",
        "(r1, fh_r1, _, bh_r1, _) = Bidirectional(LSTM(units_LSTM, return_sequences=True, return_state=True))(row1)\n",
        "(r2, fh_r2, _, bh_r2, _) = Bidirectional(LSTM(units_LSTM, return_sequences=True, return_state=True))(row2)\n",
        "(r3, fh_r3, _, bh_r3, _) = Bidirectional(LSTM(units_LSTM, return_sequences=True, return_state=True))(row3)\n",
        "(c1, fh_c1, _, bh_c1, _) = Bidirectional(LSTM(units_LSTM, return_sequences=True, return_state=True))(column1)\n",
        "(c2, fh_c2, _, bh_c2, _) = Bidirectional(LSTM(units_LSTM, return_sequences=True, return_state=True))(column2)\n",
        "(c3, fh_c3, _, bh_c3, _) = Bidirectional(LSTM(units_LSTM, return_sequences=True, return_state=True))(column3)\n",
        "\n",
        "# Se concatenan las h (forward y backward)\n",
        "h_r1 = Concatenate()([fh_r1, bh_r1])\n",
        "h_r2 = Concatenate()([fh_r2, bh_r2])\n",
        "h_r3 = Concatenate()([fh_r3, bh_r3])\n",
        "h_c1 = Concatenate()([fh_c1, bh_c1])\n",
        "h_c2 = Concatenate()([fh_c2, bh_c2])\n",
        "h_c3 = Concatenate()([fh_c3, bh_c3])\n",
        "\n",
        "# Se pasan a la capa de atencion --> se obtiene el vector de contexto\n",
        "cv_r1, _ = Attention(units_attention)(r1, h_r1)\n",
        "cv_r2, _ = Attention(units_attention)(r2, h_r2)\n",
        "cv_r3, _ = Attention(units_attention)(r3, h_r3)\n",
        "cv_c1, _ = Attention(units_attention)(c1, h_c1)\n",
        "cv_c2, _ = Attention(units_attention)(c2, h_c2)\n",
        "cv_c3, _ = Attention(units_attention)(c3, h_c3)\n",
        "\n",
        "# Se concatenan todos los vectores del contexto\n",
        "context_vector = Concatenate()([cv_r1, cv_r2, cv_r3, cv_c1, cv_c2, cv_c3])\n",
        "\n",
        "pred = Dense(1, activation='sigmoid')(context_vector)\n",
        "\n",
        "model2 = Model(inputs=patches_procesados, outputs=pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBINkCWMtoWf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9445d455-7ffd-492c-d3ea-25bb86a1703e"
      },
      "source": [
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 9, 1024)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.split (TFOpLambda)           [(None, 1, 1024), (N 0           input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat (TFOpLambda)          (None, 3, 1024)      0           tf.split[0][0]                   \n",
            "                                                                 tf.split[0][1]                   \n",
            "                                                                 tf.split[0][2]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_1 (TFOpLambda)        (None, 3, 1024)      0           tf.split[0][3]                   \n",
            "                                                                 tf.split[0][4]                   \n",
            "                                                                 tf.split[0][5]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_2 (TFOpLambda)        (None, 3, 1024)      0           tf.split[0][6]                   \n",
            "                                                                 tf.split[0][7]                   \n",
            "                                                                 tf.split[0][8]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_3 (TFOpLambda)        (None, 3, 1024)      0           tf.split[0][0]                   \n",
            "                                                                 tf.split[0][3]                   \n",
            "                                                                 tf.split[0][6]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_4 (TFOpLambda)        (None, 3, 1024)      0           tf.split[0][1]                   \n",
            "                                                                 tf.split[0][4]                   \n",
            "                                                                 tf.split[0][7]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_5 (TFOpLambda)        (None, 3, 1024)      0           tf.split[0][2]                   \n",
            "                                                                 tf.split[0][5]                   \n",
            "                                                                 tf.split[0][8]                   \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_1 (Bidirectional) [(None, 3, 18), (Non 74448       tf.concat[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_2 (Bidirectional) [(None, 3, 18), (Non 74448       tf.concat_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) [(None, 3, 18), (Non 74448       tf.concat_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_4 (Bidirectional) [(None, 3, 18), (Non 74448       tf.concat_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_5 (Bidirectional) [(None, 3, 18), (Non 74448       tf.concat_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_6 (Bidirectional) [(None, 3, 18), (Non 74448       tf.concat_5[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 18)           0           bidirectional_1[0][1]            \n",
            "                                                                 bidirectional_1[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 18)           0           bidirectional_2[0][1]            \n",
            "                                                                 bidirectional_2[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 18)           0           bidirectional_3[0][1]            \n",
            "                                                                 bidirectional_3[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 18)           0           bidirectional_4[0][1]            \n",
            "                                                                 bidirectional_4[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 18)           0           bidirectional_5[0][1]            \n",
            "                                                                 bidirectional_5[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 18)           0           bidirectional_6[0][1]            \n",
            "                                                                 bidirectional_6[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "attention_1 (Attention)         ((None, 18), (None,  391         bidirectional_1[0][0]            \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "attention_2 (Attention)         ((None, 18), (None,  391         bidirectional_2[0][0]            \n",
            "                                                                 concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "attention_3 (Attention)         ((None, 18), (None,  391         bidirectional_3[0][0]            \n",
            "                                                                 concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "attention_4 (Attention)         ((None, 18), (None,  391         bidirectional_4[0][0]            \n",
            "                                                                 concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "attention_5 (Attention)         ((None, 18), (None,  391         bidirectional_5[0][0]            \n",
            "                                                                 concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "attention_6 (Attention)         ((None, 18), (None,  391         bidirectional_6[0][0]            \n",
            "                                                                 concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_7 (Concatenate)     (None, 108)          0           attention_1[0][0]                \n",
            "                                                                 attention_2[0][0]                \n",
            "                                                                 attention_3[0][0]                \n",
            "                                                                 attention_4[0][0]                \n",
            "                                                                 attention_5[0][0]                \n",
            "                                                                 attention_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 1)            109         concatenate_7[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 449,143\n",
            "Trainable params: 449,143\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwrYhcRHh4cU"
      },
      "source": [
        "Antes de pasar al entrenamiento hay que compilarlo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rwANnRNtqTH"
      },
      "source": [
        "model2.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuA-1tH4ijmQ"
      },
      "source": [
        "Se definen los callback que se le van a aplicar:\n",
        "\n",
        "\n",
        "*   Early Stopping: sirve para monitorizar el entrenamiento y pararlo cuando se detecte que no haya mejora para los datos de validación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYC487jNttU9"
      },
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIe-ztKAkdgP"
      },
      "source": [
        "Se entrena al modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSMeY73Itu0g"
      },
      "source": [
        "epochs = 50\n",
        " \n",
        "history = model2.fit_generator(epochs=epochs, generator=train_gen, validation_data=val_gen, callbacks=early_stopping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_ehV48anGnw"
      },
      "source": [
        "Para evaluar al modelo se calcula el `accuracy` y el `balanced accuracy` para el conjunto de datos de prueba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiLFU4bhnG8z"
      },
      "source": [
        "real = test['Class']\n",
        "\n",
        "pred = model2.predict(test_gen)\n",
        "\n",
        "p=[]\n",
        "for x in pred:\n",
        "  if x > 0.5:\n",
        "    p.append(1.0)\n",
        "  else:\n",
        "    p.append(0.0)\n",
        "y_p = np.array(p)\n",
        "y_p\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_true=real, y_pred=y_p).ravel()\n",
        "print(\"Tp: \",tp,\" Fp: \",fp)\n",
        "print(\"Fn: \",fn,\" Tn:\", tn)\n",
        "\n",
        "sensitivity = tp / (tp+fn)\n",
        "specifity = tn / (fp+tn)\n",
        "\n",
        "print(\"Balanced accuracy: \", (sensitivity+specifity)/2)\n",
        "print(\"Accuracy: \", (tp+tn)/(tp+tn+fp+fn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVOjJCv-j_Qb"
      },
      "source": [
        "Se puede guardar el modelo generado para usarlo posteriormente. **Importante!** Se puede cambiar la direccion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M32wlIbUtyBi"
      },
      "source": [
        "direccion = './drive/MyDrive/TFG/model2'\n",
        "tf.keras.models.save_model(model, direccion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dYNFVECtSgJ"
      },
      "source": [
        "# Tercer modelo basado en mecanismos de atención y redes LSTM\n",
        "\n",
        "Se define el tercer modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9igWVG6Qt0XD"
      },
      "source": [
        "# Hiperparametros\n",
        "d_LSTM = 0.45\n",
        "units_LSTM = 9\n",
        "units_attention = 10\n",
        "\n",
        "# Modelo\n",
        "shape = (nb_crops*nb_crops, 1024)\n",
        "patches_procesados = tf.keras.layers.Input(shape=shape)\n",
        "patches = tf.split(patches_procesados, num_or_size_splits=9, axis=1)\n",
        "\n",
        "# Se agrupan los parches por filas\n",
        "row1 = tf.concat([patches[0], patches[1], patches[2]], axis=1, name='Concat_row1')\n",
        "row2 = tf.concat([patches[3], patches[4], patches[5]], axis=1, name='Concat_row2')\n",
        "row3 = tf.concat([patches[6], patches[7], patches[8]], axis=1, name='Concat_row3')\n",
        "\n",
        "# Se agrupan los parches por columnas\n",
        "column1 = tf.concat([patches[0], patches[3], patches[6]], axis=1)\n",
        "column2 = tf.concat([patches[1], patches[4], patches[7]], axis=1)\n",
        "column3 = tf.concat([patches[2], patches[5], patches[8]], axis=1)\n",
        "\n",
        "# Se pasa cada grupo de una capa bidireccional con unidades LSTM\n",
        "(r1, fh_r1, _, bh_r1, _) = Bidirectional(LSTM(units_LSTM, return_sequences=True, return_state=True, dropout=d_LSTM))(row1)\n",
        "(r2, fh_r2, _, bh_r2, _) = Bidirectional(LSTM(units_LSTM, return_sequences=True, return_state=True, dropout=d_LSTM))(row2)\n",
        "(r3, fh_r3, _, bh_r3, _) = Bidirectional(LSTM(units_LSTM, return_sequences=True, return_state=True, dropout=d_LSTM))(row3)\n",
        "(c1, fh_c1, _, bh_c1, _) = Bidirectional(LSTM(units_LSTM, return_sequences=True, return_state=True, dropout=d_LSTM))(column1)\n",
        "(c2, fh_c2, _, bh_c2, _) = Bidirectional(LSTM(units_LSTM, return_sequences=True, return_state=True, dropout=d_LSTM))(column2)\n",
        "(c3, fh_c3, _, bh_c3, _) = Bidirectional(LSTM(units_LSTM, return_sequences=True, return_state=True, dropout=d_LSTM))(column3)\n",
        "\n",
        "# Se concatenan las h (forward y backward)\n",
        "h_r1 = Concatenate()([fh_r1, bh_r1])\n",
        "h_r2 = Concatenate()([fh_r2, bh_r2])\n",
        "h_r3 = Concatenate()([fh_r3, bh_r3])\n",
        "h_c1 = Concatenate()([fh_c1, bh_c1])\n",
        "h_c2 = Concatenate()([fh_c2, bh_c2])\n",
        "h_c3 = Concatenate()([fh_c3, bh_c3])\n",
        "\n",
        "# Se pasan a la capa de atencion --> se obtiene el vector de contexto\n",
        "cv_r1, _ = Attention(units_attention)(r1, h_r1)\n",
        "cv_r2, _ = Attention(units_attention)(r2, h_r2)\n",
        "cv_r3, _ = Attention(units_attention)(r3, h_r3)\n",
        "cv_c1, _ = Attention(units_attention)(c1, h_c1)\n",
        "cv_c2, _ = Attention(units_attention)(c2, h_c2)\n",
        "cv_c3, _ = Attention(units_attention)(c3, h_c3)\n",
        "\n",
        "# Se concatenan todos los vectores del contexto de las filas\n",
        "rows = tf.concat([tf.expand_dims(cv_r1, axis=1), tf.expand_dims(cv_r2, axis=1), tf.expand_dims(cv_r3, axis=1)], axis=1)\n",
        "# Se concatenan todos los vectores del contexto de las columnas\n",
        "columns = tf.concat([tf.expand_dims(cv_c1, axis=1), tf.expand_dims(cv_c2, axis=1), tf.expand_dims(cv_c3, axis=1)], axis=1)\n",
        "\n",
        "# Se aplica la bidireccional a las filas y a las columnas\n",
        "(r, fh_r, _, bh_r, _) = Bidirectional(LSTM(units_LSTM, return_sequences = True, return_state=True, dropout=d_LSTM))(rows)\n",
        "(c, fh_c, _, bh_c, _) = Bidirectional(LSTM(units_LSTM, return_sequences = True, return_state=True, dropout=d_LSTM))(columns)\n",
        "\n",
        "h_r = Concatenate()([fh_r, bh_r])\n",
        "h_c = Concatenate()([fh_c, bh_c])\n",
        "\n",
        "# Se pasan a la capa de atencion --> se obtiene el vector de contexto\n",
        "cv_r, _ = Attention(units_attention)(r, h_r)\n",
        "cv_c, _ = Attention(units_attention)(c, h_c)\n",
        "\n",
        "# Se concatenan los vectores del contexto de las filas y las columnas\n",
        "context_vector = Concatenate()([cv_r, cv_c])\n",
        "\n",
        "pred = Dense(1, activation=\"sigmoid\")(context_vector)\n",
        "\n",
        "model3 = Model(inputs=patches_procesados, outputs=pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeQFZ7gTt1fW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2baf043-808c-4890-cbe1-53bdcf31bd45"
      },
      "source": [
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 9, 1024)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.split_1 (TFOpLambda)         [(None, 1, 1024), (N 0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_6 (TFOpLambda)        (None, 3, 1024)      0           tf.split_1[0][0]                 \n",
            "                                                                 tf.split_1[0][1]                 \n",
            "                                                                 tf.split_1[0][2]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_7 (TFOpLambda)        (None, 3, 1024)      0           tf.split_1[0][3]                 \n",
            "                                                                 tf.split_1[0][4]                 \n",
            "                                                                 tf.split_1[0][5]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_8 (TFOpLambda)        (None, 3, 1024)      0           tf.split_1[0][6]                 \n",
            "                                                                 tf.split_1[0][7]                 \n",
            "                                                                 tf.split_1[0][8]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_9 (TFOpLambda)        (None, 3, 1024)      0           tf.split_1[0][0]                 \n",
            "                                                                 tf.split_1[0][3]                 \n",
            "                                                                 tf.split_1[0][6]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_10 (TFOpLambda)       (None, 3, 1024)      0           tf.split_1[0][1]                 \n",
            "                                                                 tf.split_1[0][4]                 \n",
            "                                                                 tf.split_1[0][7]                 \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_11 (TFOpLambda)       (None, 3, 1024)      0           tf.split_1[0][2]                 \n",
            "                                                                 tf.split_1[0][5]                 \n",
            "                                                                 tf.split_1[0][8]                 \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_7 (Bidirectional) [(None, 3, 18), (Non 74448       tf.concat_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_8 (Bidirectional) [(None, 3, 18), (Non 74448       tf.concat_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_9 (Bidirectional) [(None, 3, 18), (Non 74448       tf.concat_8[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_10 (Bidirectional [(None, 3, 18), (Non 74448       tf.concat_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_11 (Bidirectional [(None, 3, 18), (Non 74448       tf.concat_10[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_12 (Bidirectional [(None, 3, 18), (Non 74448       tf.concat_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_8 (Concatenate)     (None, 18)           0           bidirectional_7[0][1]            \n",
            "                                                                 bidirectional_7[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_9 (Concatenate)     (None, 18)           0           bidirectional_8[0][1]            \n",
            "                                                                 bidirectional_8[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_10 (Concatenate)    (None, 18)           0           bidirectional_9[0][1]            \n",
            "                                                                 bidirectional_9[0][3]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_11 (Concatenate)    (None, 18)           0           bidirectional_10[0][1]           \n",
            "                                                                 bidirectional_10[0][3]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_12 (Concatenate)    (None, 18)           0           bidirectional_11[0][1]           \n",
            "                                                                 bidirectional_11[0][3]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_13 (Concatenate)    (None, 18)           0           bidirectional_12[0][1]           \n",
            "                                                                 bidirectional_12[0][3]           \n",
            "__________________________________________________________________________________________________\n",
            "attention_7 (Attention)         ((None, 18), (None,  391         bidirectional_7[0][0]            \n",
            "                                                                 concatenate_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "attention_8 (Attention)         ((None, 18), (None,  391         bidirectional_8[0][0]            \n",
            "                                                                 concatenate_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "attention_9 (Attention)         ((None, 18), (None,  391         bidirectional_9[0][0]            \n",
            "                                                                 concatenate_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "attention_10 (Attention)        ((None, 18), (None,  391         bidirectional_10[0][0]           \n",
            "                                                                 concatenate_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "attention_11 (Attention)        ((None, 18), (None,  391         bidirectional_11[0][0]           \n",
            "                                                                 concatenate_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "attention_12 (Attention)        ((None, 18), (None,  391         bidirectional_12[0][0]           \n",
            "                                                                 concatenate_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "tf.expand_dims (TFOpLambda)     (None, 1, 18)        0           attention_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf.expand_dims_1 (TFOpLambda)   (None, 1, 18)        0           attention_8[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf.expand_dims_2 (TFOpLambda)   (None, 1, 18)        0           attention_9[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf.expand_dims_3 (TFOpLambda)   (None, 1, 18)        0           attention_10[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.expand_dims_4 (TFOpLambda)   (None, 1, 18)        0           attention_11[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.expand_dims_5 (TFOpLambda)   (None, 1, 18)        0           attention_12[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_12 (TFOpLambda)       (None, 3, 18)        0           tf.expand_dims[0][0]             \n",
            "                                                                 tf.expand_dims_1[0][0]           \n",
            "                                                                 tf.expand_dims_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.concat_13 (TFOpLambda)       (None, 3, 18)        0           tf.expand_dims_3[0][0]           \n",
            "                                                                 tf.expand_dims_4[0][0]           \n",
            "                                                                 tf.expand_dims_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_13 (Bidirectional [(None, 3, 18), (Non 2016        tf.concat_12[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_14 (Bidirectional [(None, 3, 18), (Non 2016        tf.concat_13[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_14 (Concatenate)    (None, 18)           0           bidirectional_13[0][1]           \n",
            "                                                                 bidirectional_13[0][3]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_15 (Concatenate)    (None, 18)           0           bidirectional_14[0][1]           \n",
            "                                                                 bidirectional_14[0][3]           \n",
            "__________________________________________________________________________________________________\n",
            "attention_13 (Attention)        ((None, 18), (None,  391         bidirectional_13[0][0]           \n",
            "                                                                 concatenate_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "attention_14 (Attention)        ((None, 18), (None,  391         bidirectional_14[0][0]           \n",
            "                                                                 concatenate_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 36)           0           attention_13[0][0]               \n",
            "                                                                 attention_14[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_47 (Dense)                (None, 1)            37          concatenate_16[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 453,885\n",
            "Trainable params: 453,885\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SvF3IHA_h6A9"
      },
      "source": [
        "Antes de pasar al entrenamiento hay que compilarlo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaM6hMG_t28C"
      },
      "source": [
        "model3.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CnTYFzyirXY"
      },
      "source": [
        "Se definen los callback que se le van a aplicar:\n",
        "\n",
        "\n",
        "*   Early Stopping: sirve para monitorizar el entrenamiento y pararlo cuando se detecte que no haya mejora para los datos de validación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa-AEFOyt4et"
      },
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-OeI_k9kieQ"
      },
      "source": [
        "Se entrena al modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B10nxE6At8Ww"
      },
      "source": [
        "epochs = 50\n",
        " \n",
        "history = model3.fit_generator(epochs=epochs, generator=train_gen, validation_data=val_gen, callbacks=early_stopping)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJN85PvfnH44"
      },
      "source": [
        "Para evaluar al modelo se calcula el `accuracy` y el `balanced accuracy` para el conjunto de datos de prueba."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1E5GmXrnIM3"
      },
      "source": [
        "real = test['Class']\n",
        "\n",
        "pred = model3.predict(test_gen)\n",
        "\n",
        "p=[]\n",
        "for x in pred:\n",
        "  if x > 0.5:\n",
        "    p.append(1.0)\n",
        "  else:\n",
        "    p.append(0.0)\n",
        "y_p = np.array(p)\n",
        "y_p\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_true=real, y_pred=y_p).ravel()\n",
        "print(\"Tp: \",tp,\" Fp: \",fp)\n",
        "print(\"Fn: \",fn,\" Tn:\", tn)\n",
        "\n",
        "sensitivity = tp / (tp+fn)\n",
        "specifity = tn / (fp+tn)\n",
        "\n",
        "print(\"Balanced accuracy: \", (sensitivity+specifity)/2)\n",
        "print(\"Accuracy: \", (tp+tn)/(tp+tn+fp+fn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBEkiNgwkpY3"
      },
      "source": [
        "Se puede guardar el modelo generado para usarlo posteriormente. **Importante!** Se puede cambiar la direccion."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrbzjBpwuBcT"
      },
      "source": [
        "direccion = './drive/MyDrive/TFG/model3'\n",
        "tf.keras.models.save_model(model, direccion)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lhe_uubtsoUa"
      },
      "source": [
        "# Carga de modelos\n",
        "\n",
        "Se puede cargar cualquiera de los modelos guardados para reutilizarlos con la siguiente línea de código:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZyw8_hWuC3G"
      },
      "source": [
        "loaded_model = tf.keras.models.load_model('./drive/MyDrive/TFG/model3')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}